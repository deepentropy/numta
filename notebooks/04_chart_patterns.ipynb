{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chart Pattern Detection\n",
    "\n",
    "This notebook demonstrates numta's chart pattern detection capabilities, including head and shoulders, double/triple patterns, triangles, wedges, flags, and VCP patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numta\n",
    "from numta import (\n",
    "    # Swing detection\n",
    "    find_swing_highs, find_swing_lows, find_swing_points,\n",
    "    # Pattern detection\n",
    "    detect_head_shoulders, detect_inverse_head_shoulders,\n",
    "    detect_double_top, detect_double_bottom,\n",
    "    detect_triple_top, detect_triple_bottom,\n",
    "    detect_triangle, detect_wedge, detect_flag, detect_vcp\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Sample Data\n",
    "\n",
    "We'll generate price data with some embedded patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "n = 300\n",
    "\n",
    "# Generate a price series with trends\n",
    "trend = np.sin(np.linspace(0, 4*np.pi, n)) * 20\n",
    "noise = np.cumsum(np.random.randn(n) * 0.5)\n",
    "close = 100 + trend + noise\n",
    "\n",
    "# Create OHLC data\n",
    "df = pd.DataFrame({\n",
    "    'open': close + np.random.randn(n) * 0.5,\n",
    "    'high': close + np.abs(np.random.randn(n)) * 1.5,\n",
    "    'low': close - np.abs(np.random.randn(n)) * 1.5,\n",
    "    'close': close,\n",
    "    'volume': np.random.randint(1000, 10000, n).astype(float)\n",
    "})\n",
    "\n",
    "print(f\"Sample data: {n} bars\")\n",
    "print(f\"Price range: {df['close'].min():.2f} - {df['close'].max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Swing Point Detection\n",
    "\n",
    "Before detecting patterns, we need to identify swing highs and lows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find swing highs and lows\n",
    "highs = df['high'].values\n",
    "lows = df['low'].values\n",
    "\n",
    "# order parameter controls the number of bars on each side\n",
    "swing_highs = find_swing_highs(highs, order=5)\n",
    "swing_lows = find_swing_lows(lows, order=5)\n",
    "\n",
    "print(f\"Swing highs found: {len(swing_highs)}\")\n",
    "print(f\"Swing lows found: {len(swing_lows)}\")\n",
    "\n",
    "# Get combined swing points\n",
    "swing_points = find_swing_points(highs, lows, order=5)\n",
    "print(f\"\\nTotal swing points: {len(swing_points)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Head and Shoulders\n",
    "\n",
    "The head and shoulders pattern is a reversal pattern consisting of three peaks, with the middle peak (head) being the highest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Head and Shoulders (Bearish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect head and shoulders patterns\n",
    "hs_patterns = detect_head_shoulders(highs, lows, order=5)\n",
    "\n",
    "print(f\"Head and Shoulders patterns found: {len(hs_patterns)}\")\n",
    "\n",
    "for pattern in hs_patterns[:3]:  # Show first 3\n",
    "    print(f\"\\nPattern at indices {pattern.start_index} - {pattern.end_index}\")\n",
    "    print(f\"  Confidence: {pattern.confidence:.2f}\")\n",
    "    print(f\"  Left shoulder: {pattern.left_shoulder_index}\")\n",
    "    print(f\"  Head: {pattern.head_index}\")\n",
    "    print(f\"  Right shoulder: {pattern.right_shoulder_index}\")\n",
    "    print(f\"  Neckline: {pattern.neckline_slope:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse Head and Shoulders (Bullish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect inverse head and shoulders patterns\n",
    "ihs_patterns = detect_inverse_head_shoulders(highs, lows, order=5)\n",
    "\n",
    "print(f\"Inverse Head and Shoulders patterns found: {len(ihs_patterns)}\")\n",
    "\n",
    "for pattern in ihs_patterns[:3]:\n",
    "    print(f\"\\nPattern at indices {pattern.start_index} - {pattern.end_index}\")\n",
    "    print(f\"  Confidence: {pattern.confidence:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double and Triple Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double Top and Double Bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double Top (bearish reversal)\n",
    "double_tops = detect_double_top(highs, lows, order=5)\n",
    "print(f\"Double Top patterns: {len(double_tops)}\")\n",
    "\n",
    "for pattern in double_tops[:2]:\n",
    "    print(f\"  Indices: {pattern.start_index} - {pattern.end_index}, Confidence: {pattern.confidence:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double Bottom (bullish reversal)\n",
    "double_bottoms = detect_double_bottom(highs, lows, order=5)\n",
    "print(f\"Double Bottom patterns: {len(double_bottoms)}\")\n",
    "\n",
    "for pattern in double_bottoms[:2]:\n",
    "    print(f\"  Indices: {pattern.start_index} - {pattern.end_index}, Confidence: {pattern.confidence:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triple Top and Triple Bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Triple Top (bearish reversal)\n",
    "triple_tops = detect_triple_top(highs, lows, order=5)\n",
    "print(f\"Triple Top patterns: {len(triple_tops)}\")\n",
    "\n",
    "# Triple Bottom (bullish reversal)\n",
    "triple_bottoms = detect_triple_bottom(highs, lows, order=5)\n",
    "print(f\"Triple Bottom patterns: {len(triple_bottoms)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triangles\n",
    "\n",
    "Triangles are continuation patterns characterized by converging trendlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect triangles (ascending, descending, symmetrical)\n",
    "triangles = detect_triangle(highs, lows, order=5)\n",
    "\n",
    "print(f\"Triangle patterns found: {len(triangles)}\")\n",
    "\n",
    "for pattern in triangles[:3]:\n",
    "    print(f\"\\n{pattern.triangle_type.title()} Triangle\")\n",
    "    print(f\"  Indices: {pattern.start_index} - {pattern.end_index}\")\n",
    "    print(f\"  Confidence: {pattern.confidence:.2f}\")\n",
    "    print(f\"  Upper trendline slope: {pattern.upper_trendline_slope:.4f}\")\n",
    "    print(f\"  Lower trendline slope: {pattern.lower_trendline_slope:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wedges\n",
    "\n",
    "Wedges are similar to triangles but both trendlines slope in the same direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect wedges (rising, falling)\n",
    "wedges = detect_wedge(highs, lows, order=5)\n",
    "\n",
    "print(f\"Wedge patterns found: {len(wedges)}\")\n",
    "\n",
    "for pattern in wedges[:3]:\n",
    "    print(f\"\\n{pattern.wedge_type.title()} Wedge\")\n",
    "    print(f\"  Indices: {pattern.start_index} - {pattern.end_index}\")\n",
    "    print(f\"  Confidence: {pattern.confidence:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flags and Pennants\n",
    "\n",
    "Flags are continuation patterns that form after a strong move."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect flags and pennants\n",
    "flags = detect_flag(highs, lows, close, order=5)\n",
    "\n",
    "print(f\"Flag patterns found: {len(flags)}\")\n",
    "\n",
    "for pattern in flags[:3]:\n",
    "    print(f\"\\n{pattern.flag_type.title()}\")\n",
    "    print(f\"  Indices: {pattern.start_index} - {pattern.end_index}\")\n",
    "    print(f\"  Pole direction: {pattern.pole_direction}\")\n",
    "    print(f\"  Confidence: {pattern.confidence:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volatility Contraction Pattern (VCP)\n",
    "\n",
    "The VCP is characterized by decreasing price swings (volatility contraction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect VCP patterns\n",
    "vcp_patterns = detect_vcp(highs, lows, order=5)\n",
    "\n",
    "print(f\"VCP patterns found: {len(vcp_patterns)}\")\n",
    "\n",
    "for pattern in vcp_patterns[:3]:\n",
    "    print(f\"\\nVCP Pattern\")\n",
    "    print(f\"  Indices: {pattern.start_index} - {pattern.end_index}\")\n",
    "    print(f\"  Contraction count: {pattern.contraction_count}\")\n",
    "    print(f\"  Confidence: {pattern.confidence:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern Confidence Scores\n",
    "\n",
    "All pattern detection functions return a confidence score between 0 and 1. Higher scores indicate patterns that more closely match the ideal characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all patterns and sort by confidence\n",
    "all_patterns = []\n",
    "\n",
    "for p in hs_patterns:\n",
    "    all_patterns.append(('Head & Shoulders', p.confidence, p.start_index, p.end_index))\n",
    "\n",
    "for p in ihs_patterns:\n",
    "    all_patterns.append(('Inverse H&S', p.confidence, p.start_index, p.end_index))\n",
    "\n",
    "for p in double_tops:\n",
    "    all_patterns.append(('Double Top', p.confidence, p.start_index, p.end_index))\n",
    "\n",
    "for p in double_bottoms:\n",
    "    all_patterns.append(('Double Bottom', p.confidence, p.start_index, p.end_index))\n",
    "\n",
    "for p in triangles:\n",
    "    all_patterns.append((f'{p.triangle_type} Triangle', p.confidence, p.start_index, p.end_index))\n",
    "\n",
    "# Sort by confidence\n",
    "all_patterns.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Top patterns by confidence:\")\n",
    "for name, conf, start, end in all_patterns[:10]:\n",
    "    print(f\"  {name}: {conf:.3f} (bars {start}-{end})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Pandas Accessor\n",
    "\n",
    "Pattern detection is also available through the `.ta` accessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all patterns\n",
    "patterns = df.ta.find_patterns(pattern_type='all', order=5)\n",
    "print(f\"Total patterns found: {len(patterns)}\")\n",
    "\n",
    "# Find specific pattern types\n",
    "double_patterns = df.ta.find_patterns(pattern_type='double')\n",
    "print(f\"Double patterns: {len(double_patterns)}\")\n",
    "\n",
    "triangles = df.ta.find_patterns(pattern_type='triangle')\n",
    "print(f\"Triangle patterns: {len(triangles)}\")\n",
    "\n",
    "head_shoulders = df.ta.find_patterns(pattern_type='head_shoulders')\n",
    "print(f\"Head & Shoulders patterns: {len(head_shoulders)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- See `05_harmonic_patterns.ipynb` for harmonic pattern recognition (Gartley, Butterfly, etc.)\n",
    "- See `07_visualization.ipynb` for visualizing patterns with lwcharts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
